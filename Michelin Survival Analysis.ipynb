{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michelin survivor\n",
    "Michelin-rated restaurants are some of the highest-grossing businesses in the fine-dining industry – a $10 billion market in the U.S. Inversely, losing a Michelin star can make a business less profitable, with up to 40% of these businesses closing within 5 years. At Insight, I used Yelp reviews to develop a product that forecasts the risk of a restaurant losing a Michelin star and provides actionable insights to restaurateurs and investors on how to improve if their business is deemed at risk. Restaurants have vastly different timelines - from opening, getting Michelin-rated, to closing shop - so wrangling 100k Yelp reviews into usable time-series was a significant challenge to overcome, and vital in broader risk assessment and survival analysis problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "michelin_data    = pd.read_csv('michelin_nyc_stars.csv')\n",
    "michelin_data    = michelin_data.iloc[:,1:]\n",
    "\n",
    "michelin_data['name'] = michelin_data['name'].replace(to_replace = {'breslin': 'the-breslin',\n",
    "                           'cho-dang-gol': 'cho-dang-gol-korean-restaurant',\n",
    "                            'el-parador': 'el-parador-cafe',\n",
    "                            'ginza-onodera': 'sushi-ginza-onodera',\n",
    "                            'good-fork': 'the-good-fork',\n",
    "                            'grammercy-tavern': 'gramercy-tavern',\n",
    "                                                   'great-ny-noodletown': 'great-ny-noodle-town',\n",
    "                                                    'katzs': 'katzs-delicatessen',\n",
    "                                                    'kurumazushi': 'kuruma-zushi',\n",
    "                                                  'modern' : 'the-modern',\n",
    "                                                   'modern,-the': 'the-modern',\n",
    "                                                  'sevilla': 'sevilla-restaurant',\n",
    "                                                   'spotted-pig' : 'the-spotted-pig'})\n",
    "\n",
    "michelin_data['name'] = (michelin_data['name'].str.replace('é', 'e').str.replace('ë', 'e').str.replace('ü', 'u'))\n",
    "michelin_data         = michelin_data.drop_duplicates(keep = 'first')\n",
    "michelin_data         = michelin_data.drop([216,217], axis = 0)\n",
    "\n",
    "dupes = michelin_data.name[michelin_data.name.duplicated()]\n",
    "dupes = michelin_data.loc[michelin_data.name.duplicated(keep = False)].sort_values(by = 'name')\n",
    "\n",
    "# for each in dupes\n",
    "# dupes.loc[dupes.name == 'cafe'] = dupes.iloc[0,:] + dupes.iloc[1,:]\n",
    "# for each in dupes.name.unique():\n",
    "\n",
    "new = pd.DataFrame(columns = dupes.columns)\n",
    "i = 0\n",
    "for each in dupes.name.unique():\n",
    "    new.loc[i] = dupes.loc[(dupes.name==each)].sum(axis = 0, numeric_only = True)\n",
    "    i+=1\n",
    "new['name'] = dupes.name.unique()\n",
    "\n",
    "michelin_data = michelin_data.drop(dupes.index, axis = 0)\n",
    "michelin_data = pd.concat([michelin_data,new], axis = 0).reset_index(drop = True)\n",
    "michelin_data['name'] = (michelin_data['name'].str.replace('gunter-seeger-ny', 'gunter-seeger'))\n",
    "michelin_data.name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load helper_functions.py\n",
    "import numpy as np\n",
    "from scipy.stats import linregress, kurtosis, skew\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_review_topic_weights():\n",
    "    new_data  = pd.read_csv('yelp_data_additional.csv', header = None, names = ['restaurant', 'date', 'rating', 'review'])\n",
    "    old_data  = pd.read_csv('michelin_yelp_reviews.csv')\n",
    "\n",
    "    yelp_data = pd.concat([new_data, old_data], axis = 0)\n",
    "    yelp_data['restaurant'] = (yelp_data['restaurant'].str.replace('é', 'e').str.replace('ë', 'e')\n",
    "                               .str.replace('ū', 'u').str.replace('ü', 'u').str.replace('gunter-seeger-ny', 'gunter-seeger')\n",
    "                              )\n",
    "\n",
    "    yelp_data = yelp_data.drop_duplicates(keep = 'first')\n",
    "\n",
    "    yelp_data['review'] = (yelp_data.review.str.replace('\\\\\\\\xc2', '')\n",
    "                           .str.replace('\\\\\\\\xa0', '')\n",
    "                            .str.replace('\\\\\\xa0', '')\n",
    "                           .str.lower()\n",
    "                           .str.replace('\\d+', '')\n",
    "                           .str.replace(r'[^\\w\\s]+', '')\n",
    "                            .str.replace('cocktails', 'cocktail')\n",
    "                            .str.replace('zzs', '')\n",
    "                            .str.replace('xc', '')\n",
    "                            .str.replace('xa', '')\n",
    "                            .str.replace('zz', '')\n",
    "                            .str.replace('       ', '')\n",
    "                            .str.replace('eellent', 'excellent')\n",
    "                            .str.replace(r'\\bthe\\b', '')\n",
    "                            .str.replace(r'\\band\\b', '')\n",
    "                            .str.replace(r'\\bas\\b', '')\n",
    "                            .str.replace(r'\\bof\\b', '') )\n",
    "\n",
    "    yelp_data['date']   = pd.to_datetime(yelp_data.date.str.replace('Updatedreview', ''))\n",
    "    \n",
    "    yelp_df   = yelp_data.copy().reset_index(drop = True)\n",
    "    \n",
    "    extra_words = ['ve', 'like', 'got', 'just',\n",
    "                       'don', 'really', 'said', 'told', 'ok',\n",
    "                       'came', 'went', 'did', 'didn', 'good', 'momofuku', 'peter', 'luger' ,'lugers',\n",
    "                  'katzs']\n",
    "\n",
    "    stop_words = text.ENGLISH_STOP_WORDS.union(extra_words)\n",
    "    tfidf      = TfidfVectorizer(stop_words=stop_words, min_df=10, max_df=0.5,\n",
    "                                ngram_range=(1,1), token_pattern='[a-z][a-z]+')\n",
    "    dicty = {'noodles' : 'noodle', 'dishes': 'dish',\n",
    "                 'buns': 'bun', 'asked' : 'ask',\n",
    "                 'pieces' :'piece', 'burgers' : 'burger' ,\n",
    "                'minutes' : 'minute', 'orders' : 'order', 'waffles' :'waffle'}\n",
    "\n",
    "    def replace_words(text, dicty):\n",
    "            for i,j in dicty.items():\n",
    "                text = text.replace(i,j)\n",
    "            return text\n",
    "\n",
    "    reviews_processed   = [replace_words(w, dicty) for w in yelp_data.review]\n",
    "    review_vectors      = tfidf.fit_transform(reviews_processed )\n",
    "    num_topics          = 10\n",
    "    nmf_reviews         = NMF(n_components=num_topics)\n",
    "    topic_weights       = nmf_reviews.fit_transform(review_vectors)\n",
    "    no_topics = num_topics\n",
    "    no_top_words = 6\n",
    "\n",
    "    def display_topics(model, feature_names, num_topics, no_top_words):\n",
    "        for topic_idx, topic in enumerate(model.components_):\n",
    "            if topic_idx < num_topics:\n",
    "                print(\"{:11}\".format(\"Topic %d:\" %(topic_idx)), end='')\n",
    "                print(\", \".join(['{:04.3f}*'.format(topic[i])+feature_names[i] \\\n",
    "                                 for i in topic.argsort()[:-no_top_words-1:-1]]))\n",
    "\n",
    "    print('Top topics + words for all reviews')\n",
    "    print('-'*39)\n",
    "    display_topics(nmf_reviews, tfidf.get_feature_names(), no_topics, no_top_words)\n",
    "\n",
    "\n",
    "\n",
    "    topics = {0:'wait time', 1:'food1', 2:'food2',\n",
    "                          3:'food3', 4:'service', 5: 'food4',\n",
    "                          6: 'food5', 7: 'food6', 8: 'menu', 9: 'value'}\n",
    "\n",
    "\n",
    "    new_topics = ['wait time', 'menu', 'food_quality', 'service', 'value']\n",
    "\n",
    "\n",
    "    topic_weights_df = pd.DataFrame(normalize(topic_weights, norm='l1'), columns = list(topics.values()))\n",
    "\n",
    "    topic_weights_df['menu']         =   topic_weights_df['menu']\n",
    "    topic_weights_df['food_quality'] = (topic_weights_df['food1'] + topic_weights_df['food2']\n",
    "                                    + topic_weights_df['food3'] +  topic_weights_df['food4'] + topic_weights_df['food5']\n",
    "                                        +topic_weights_df['food6'])/3\n",
    "    # topic_weights_df.loc[yelp_data.rating <= 3][new_topics] = -1* topic_weights_df.loc[yelp_data.rating <= 3][new_topics]\n",
    "\n",
    "\n",
    "    def threshold(number):\n",
    "            if abs(number) > .25:\n",
    "                return(int(1)) * np.sign(number)\n",
    "            else:\n",
    "                return(int(0))\n",
    "    neg_ind = yelp_df.loc[yelp_df['rating']<=3].index.values\n",
    "    for each in new_topics:\n",
    "        topic_weights_df[each].loc[neg_ind] =  -1* topic_weights_df[each].loc[neg_ind]\n",
    "        topic_weights_df[each] =  topic_weights_df[each].apply(threshold).astype(int)\n",
    "\n",
    "    yelp_data = yelp_df.copy()\n",
    "    yelp_data  = pd.concat([yelp_df, topic_weights_df[new_topics]], axis = 1)\n",
    "    \n",
    "    return yelp_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_subset_dict(predict_year, michelin_data, yelp_data):\n",
    "\n",
    "    evaluation_cutoff = 100 # in days\n",
    "    year_data         = dict()\n",
    "\n",
    "    next_year        = 'stars_{}'.format(str(predict_year))\n",
    "    this_year        = 'stars_{}'.format(str(predict_year-1))\n",
    "    michelin_subset  = michelin_data.loc[michelin_data[this_year] != 0]\n",
    "    michelin_subset  = michelin_subset.set_index('name', drop = True)\n",
    "    michelin_subset  = michelin_subset.loc[list(set(michelin_subset.index) & set(yelp_data.restaurant.unique()))]\n",
    "\n",
    "    try:\n",
    "        target = pd.Series((michelin_subset[next_year] - michelin_subset[this_year]) < 0, index = michelin_subset.index).astype(int)\n",
    "    except:\n",
    "        target = []\n",
    "\n",
    "    def check_if_subset(restaurant):\n",
    "        return restaurant in michelin_subset.index\n",
    "\n",
    "    yelp_subset_index = yelp_data.restaurant.apply(check_if_subset)\n",
    "    subset_data  = yelp_data.loc[yelp_subset_index]\n",
    "\n",
    "    subset_data  = subset_data.loc[(subset_data.date < dt.datetime(predict_year, 1, 1)\n",
    "                                   -  dt.timedelta(days = evaluation_cutoff)) ]\n",
    "    \n",
    "    year_data['michelin'] = michelin_subset\n",
    "    year_data['target']   = target\n",
    "    year_data['yelp']     = subset_data\n",
    "\n",
    "    return year_data\n",
    "\n",
    "def trend(series):\n",
    "    try:\n",
    "        slope                     = linregress(range(0,len(series)), series)[0]\n",
    "    except:\n",
    "        slope = 0\n",
    "    return slope\n",
    "\n",
    "def count_char(series):\n",
    "    num_char = 0\n",
    "    for each in series:\n",
    "        num_char += len(each)\n",
    "    try:\n",
    "        count =  num_char /len(series)\n",
    "    except:\n",
    "        count = 0\n",
    "    return count\n",
    "\n",
    "def make_div_features(restaurant_df, predict_year):\n",
    "\n",
    "    rating_cols = ['slope', 'mean', 'kurtosis', 'skew', 'median', 'std',\n",
    "                'var', 'number_reviews', 'avg_length_reviews']\n",
    "\n",
    "    review_cols = ['food_quality', 'menu', 'service', 'value', 'wait time']\n",
    "\n",
    "    div_df   = pd.DataFrame(columns = rating_cols + review_cols)\n",
    "    total_df = div_df.copy()\n",
    "    \n",
    "\n",
    "    # make relative time series\n",
    "    restaurant_df.index          = pd.date_range(start = '2000-01-01', end =  '2000-12-31', periods=restaurant_df.shape[0])\n",
    "    #resample four times for different measures\n",
    "    div_df['mean']               = restaurant_df.rating.resample('4M').mean().reset_index(drop = True)\n",
    "    div_df['slope']              = restaurant_df.rating.resample('4M').apply(trend).reset_index(drop = True)\n",
    "    div_df['kurtosis']           = restaurant_df.rating.resample('4M').apply(kurtosis).reset_index(drop = True)\n",
    "    div_df['std']                = restaurant_df.rating.resample('4M').apply(np.std).reset_index(drop = True)\n",
    "    div_df['var']                = restaurant_df.rating.resample('4M').apply(np.std).reset_index(drop = True) ** 2\n",
    "    div_df['median']             = restaurant_df.rating.resample('4M').apply(np.median).reset_index(drop = True)\n",
    "    div_df['skew']               = restaurant_df.rating.resample('4M').apply(skew).reset_index(drop = True)\n",
    "    div_df['number_reviews']     = restaurant_df.rating.resample('4M').apply(len).reset_index(drop = True)\n",
    "    div_df['avg_length_reviews'] = restaurant_df.review.resample('4M').apply(count_char).reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "    total_df['mean']               = [restaurant_df.rating.mean(), restaurant_df.rating.mean()]\n",
    "    total_df['slope']              = [trend(restaurant_df.rating),trend(restaurant_df.rating)]\n",
    "    total_df['kurtosis']           = [restaurant_df.rating.kurtosis(), restaurant_df.rating.kurtosis()]\n",
    "    total_df['std']                = [np.std(restaurant_df.rating), np.std(restaurant_df.rating)]\n",
    "    total_df['var']                = [np.std(restaurant_df.rating) ** 2, np.std(restaurant_df.rating) ** 2]\n",
    "    total_df['median']             = [np.median(restaurant_df.rating), np.median(restaurant_df.rating)]\n",
    "    total_df['skew']               = [skew(restaurant_df.rating), skew(restaurant_df.rating)]\n",
    "    total_df['number_reviews']     = [len(restaurant_df.rating), len(restaurant_df.rating)]\n",
    "    total_df['avg_length_reviews'] = [np.sum(restaurant_df.review.apply(len))/restaurant_df.shape[0], np.sum(restaurant_df.review.apply(len))/restaurant_df.shape[0]\n",
    "                                     ]\n",
    "    \n",
    "\n",
    "    for each in review_cols:\n",
    "        div_df[each]   = restaurant_df[each].resample('4M').mean().reset_index(drop = True)\n",
    "        total_df[each] = restaurant_df[each].mean()\n",
    "\n",
    "    ratings = dict()\n",
    "    ratings['divs']  = div_df\n",
    "    ratings['total'] = total_df\n",
    "    ratings['total']['first_review']       = [((dt.datetime(predict_year, 1, 1)  -  dt.timedelta(days = 100)) - min(restaurant_df['date'])).days, 0]\n",
    "\n",
    "    return ratings\n",
    "\n",
    "def process_restaurant_yelp_data(restaurant, data_df, predict_year):\n",
    "    yelp_df          = data_df['yelp']\n",
    "    michelin_df      = data_df['michelin']\n",
    "    resto_df         = yelp_df.loc[yelp_df.restaurant == restaurant]\n",
    "    feature_dict     = make_div_features(resto_df, predict_year)\n",
    "\n",
    "\n",
    "    return feature_dict\n",
    "\n",
    "\n",
    "def get_features_and_predicted(data_df, predict_year):\n",
    "\n",
    "    columns = ['name', 'first_review', 'n_stars']\n",
    "    measures = ['slope', 'mean', 'kurtosis', 'skew', 'median', 'std',\n",
    "                'var', 'number_reviews', 'avg_length_reviews', 'food_quality', 'menu', 'service', 'value', 'wait time']\n",
    "\n",
    "    for measure in measures:\n",
    "        for div in range(0,5):\n",
    "            if div < 4:\n",
    "                columns.append('div{}_{}'.format(div+1, measure))\n",
    "            else:\n",
    "                columns.append('total_{}'.format(measure))\n",
    "\n",
    "\n",
    "    feature_set        = pd.DataFrame(columns = columns, index = data_df['yelp'].restaurant.unique())\n",
    "\n",
    "\n",
    "    ndivs = 5\n",
    "    for resto in feature_set.index:\n",
    "\n",
    "        rating_features = process_restaurant_yelp_data(resto, data_df, predict_year)\n",
    "\n",
    "\n",
    "        row = dict()\n",
    "        row['name'] = resto\n",
    "        row['first_review'] = rating_features['total']['first_review'].iloc[0]\n",
    "        row['n_stars']      = data_df['michelin'].loc[resto]['stars_{}'.format(str(predict_year-1))]\n",
    "        for measure in measures:\n",
    "            for div in range(0,ndivs):\n",
    "                if div+1 < ndivs:\n",
    "                    try:\n",
    "                        row['div{}_{}'.format(div+1, measure)] = rating_features['divs'][measure][div]\n",
    "                    except:\n",
    "                         row['div{}_{}'.format(div+1, measure)] = rating_features['divs'][measure][0]\n",
    "\n",
    "                else:\n",
    "                    row['total_{}'.format(measure)] = rating_features['total'][measure].loc[0]\n",
    "\n",
    "                feature_set.loc[resto] = row\n",
    "\n",
    "    feature_set = feature_set.fillna(feature_set.mean(axis = 0))\n",
    "    target      = pd.DataFrame(data_df['target'], columns = ['target'])\n",
    "    target['name'] = target.index\n",
    "    target      = target.reset_index(drop = True)\n",
    "    full_data   = feature_set.merge(target, how = 'left', on = 'name')\n",
    "    full_data   = full_data.set_index('name', drop = True)\n",
    "\n",
    "    y           = full_data.target\n",
    "    X           = full_data.drop(columns = 'target')\n",
    "    X           = X.fillna(X.mean())\n",
    "    X           = scale_X(X)\n",
    "    X           = pd.get_dummies(X, columns = ['n_stars'], drop_first= True, prefix = 'michelin_')\n",
    "\n",
    "    return X , y\n",
    "\n",
    "def scale_X(X):\n",
    "    scaler  = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "#     X = X.set_index('name', drop = True)\n",
    "    scaler.fit(X)\n",
    "    return pd.DataFrame(scaler.transform(X), columns = X.columns, index = X.index).fillna(0)\n",
    "\n",
    "\n",
    "# over sample minority\n",
    "\n",
    "\n",
    "def make_resampled(X,y):\n",
    " #input DataFrame\n",
    " #X →Independent Variable in DataFrame\\\n",
    " #y →dependent Variable in Pandas DataFrame format\n",
    "    sm = SMOTE()\n",
    "    X_new, y_new = sm.fit_sample(X, y)\n",
    "\n",
    "    return  pd.DataFrame(X_new, columns = X.columns), pd.Series(y_new)\n",
    "\n",
    "def get_train_and_holdout(predict_year, michelin_data, yelp_data):\n",
    "    train                      = {'X' : pd.DataFrame(), 'y': pd.Series()}\n",
    "    holdout                    = dict()\n",
    "\n",
    "    predict_year_dict          = get_subset_dict(predict_year, michelin_data, yelp_data)\n",
    "    holdout['X'], holdout['y'] = get_features_and_predicted(predict_year_dict, predict_year)\n",
    "\n",
    "\n",
    "    for year in range(2008, predict_year):\n",
    "        year_dict = dict()\n",
    "        year_dict    =  get_subset_dict(year, michelin_data, yelp_data)#.drop('food_quality'4))\n",
    "        year_dict['X'], year_dict['y']   = get_features_and_predicted(year_dict, year)\n",
    "        train['X']                =  pd.concat([train['X'], year_dict['X']], axis = 0)\n",
    "        train['y']                =  pd.concat([train['y'], year_dict['y']], axis = 0)\n",
    "    return train, holdout\n",
    "\n",
    "\n",
    "def run_model(train, holdout, cols, clf = LogisticRegression(), thresh = .5, plot_on = True):\n",
    "\n",
    "    clf.fit(train['X'][cols], train['y'])\n",
    "    predicted = clf.predict(holdout['X'][cols])\n",
    "    probs = clf.predict_proba(holdout['X'][cols])\n",
    "    probs = probs[:,1]\n",
    "    probs = np.where(probs > thresh, 1, 0)\n",
    "\n",
    "    print('Mean Accuracy: %0.2f' % metrics.accuracy_score(holdout['y'], predicted) )\n",
    "    print('Classification Report: \\n', metrics.classification_report(holdout['y'], predicted))\n",
    "    print('Confusion Matrix: \\n', metrics.confusion_matrix(holdout['y'], predicted))\n",
    "    print(metrics.accuracy_score(holdout['y'], predicted))\n",
    "\n",
    "    fpr, tpr, threshold = metrics.roc_curve(holdout['y'], probs)\n",
    "\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.savefig('roc.png', dpi = 300)\n",
    "    plt.show()\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig('roc.png')\n",
    "    \n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "def get_rfecv_features(train, clf = LogisticRegression()):\n",
    "    rfecv = RFECV(estimator=clf, step=1, cv=10,\n",
    "                  scoring='roc_auc', min_features_to_select = 10)\n",
    "\n",
    "    rfecv.fit(train['X'], train['y'])\n",
    "    selected_cols = train['X'].columns[rfecv.support_]\n",
    "\n",
    "    print(\"Optimal number of features :{}\".format(rfecv.n_features_) )\n",
    "\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    plt.show()\n",
    "    return selected_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process yelp data for text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_data = get_review_topic_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get train and holdout data for a specific year\n",
    "Holdout data corresponds to all the yelp data up to 1 year + 100 days before 1/1 of the predicted year, holdout corresponds to all the data including up to 100 days before the predicted year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_year   = 2009\n",
    "train, holdout = get_train_and_holdout(predict_year, michelin_data, yelp_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "cafe-boulud        0.384615\n",
       "craft              0.384615\n",
       "cru                0.586014\n",
       "daniel             0.662937\n",
       "gramercy-tavern    0.800000\n",
       "the-modern         0.348252\n",
       "wallse             0.471329\n",
       "a-voce             0.310490\n",
       "annisa             0.241958\n",
       "aureole            0.387413\n",
       "bouley             0.393007\n",
       "cafe-gray          0.517483\n",
       "danube             0.444755\n",
       "devi               0.674126\n",
       "fleur-de-sel       0.507692\n",
       "la-goulue          0.495105\n",
       "le-bernardin       0.541259\n",
       "per-se             1.000000\n",
       "perry-street       0.451748\n",
       "picholine          0.000000\n",
       "vong               0.386014\n",
       "wd-50              0.377622\n",
       "Name: first_review, dtype: float64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['X'].first_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize correlations accross the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(32, 32))\n",
    "corr = train['X'].corr(method = 'pearson')\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(corr, vmax=1, square=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a baseline model with logsitc regression to evaluate Michelin survival in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf = run_model(train, holdout, cols = train['X'].columns.values,  clf = clf)\n",
    "score = cross_val_score(clf, train['X'], train['y'], cv = 10, scoring= 'roc_auc').mean()\n",
    "print('Cross validation score: {}'.format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample to balanced classes using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_train = {'X' : pd.DataFrame(), 'y': pd.Series()}\n",
    "resampled_train['X'], resampled_train['y'] = make_resampled(train['X'], train['y'])\n",
    "\n",
    "clf = LogisticRegression(C = .1)\n",
    "clf = run_model(resampled_train, resampled_train, cols = resampled_train['X'].columns,  clf = clf)\n",
    "\n",
    "score = cross_val_score(clf, resampled_train['X'], resampled_train['y'], cv = 10, scoring= 'roc_auc').mean()\n",
    "print('Cross validation score: {}'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_abs = pd.Series(clf.coef_[0], index = train['X'].columns).sort_values(ascending = True)\n",
    "coefs_abs.plot.barh(figsize = (15,15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = .1)\n",
    "clf = run_model(resampled_train, holdout, cols = resampled_train['X'].columns,  clf = clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf           = LogisticRegression( C = .1)\n",
    "selected_cols = get_rfecv_features(resampled_train, clf = clf)\n",
    "\n",
    "run_model(resampled_train, holdout,  clf = clf, cols = selected_cols)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = list()\n",
    "topics = ['food_quality', 'wait time', 'service', 'value', 'menu']\n",
    "for each in train['X'].columns:\n",
    "    for topic in topics:\n",
    "        if topic in each:\n",
    "            my_cols.append(each)\n",
    "no_text = dict()            \n",
    "no_text['X'] = train['X'].drop(my_cols, axis = 1)\n",
    "no_text['y'] = train['y'].copy()\n",
    "\n",
    "run_model(no_text, holdout, cols = no_text['X'].columns)\n",
    "\n",
    "resampled_train = {'X' : pd.DataFrame(), 'y': pd.Series()}\n",
    "resampled_train['X'], resampled_train['y'] = make_resampled(no_text['X'],no_text['y'])\n",
    "\n",
    "clf = LogisticRegression(C = .1)\n",
    "clf = run_model(resampled_train, holdout, cols = resampled_train['X'].columns,  clf = clf)\n",
    "\n",
    "score = cross_val_score(clf, resampled_train['X'], resampled_train['y'], cv = 10, scoring= 'roc_auc').mean()\n",
    "print('Cross validation score: {}'.format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate insights for at-risk restaurants for 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "predict_year   = 2018\n",
    "\n",
    "def produce_results(predict_year, michelin_data, yelp_data):\n",
    "    \n",
    "    train, holdout = get_train_and_holdout(predict_year, michelin_data, yelp_data)\n",
    "    df = holdout['X'].copy()\n",
    "    resampled_train = {'X' : pd.DataFrame(), 'y': pd.Series()}\n",
    "    resampled_train['X'], resampled_train['y'] = make_resampled(train['X'], train['y'])\n",
    "\n",
    "    clf  = LogisticRegression(C = .1, random_state=0)\n",
    "    clf.fit(resampled_train['X'], resampled_train['y'])\n",
    "    clf.predict_proba(df)[:1]\n",
    "\n",
    "    probs = -1* minmax_scale(clf.predict_proba(holdout['X'])[:,1], feature_range = (-.99, .99))\n",
    "    probs = pd.Series(probs, index = holdout['X'].index)\n",
    "    df['probs']   = probs \n",
    "    df['at_risk'] = (df['probs'].apply(np.sign)  + 1)/2\n",
    "    df['actual'] = holdout['y']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "results_2015 = produce_results(predict_year, michelin_data, yelp_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['daniel', 'danji', 'oceana', 'a-voce', 'a-voce-columbus', 'annisa',\n",
       "       'le-restaurant', 'rouge-tomate', 'tamarind-tribeca', 'wd-50'],\n",
       "      dtype='object', name='name')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2015.index[results_2015.actual == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = -1* minmax_scale(clf.predict_proba(holdout['X'])[:,1], feature_range = (-.99, .99))\n",
    "probs = pd.Series(probs, index = holdout['X'].index)\n",
    "df_2020 = holdout['X'].copy()\n",
    "df_2020['probs']   = probs \n",
    "def risk_thresh(p):\n",
    "    if p < 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df_2020['at_risk'] = (df_2020['probs'].apply(risk_thresh))\n",
    "df_2020.head()\n",
    "df_2020.to_csv('michelin_2020_model_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_risk     = probs[probs < 0]probs = -1* minmax_scale(clf.predict_proba(holdout['X'])[:,1], feature_range = (-.99, .99))\n",
    "probs = pd.Series(probs, index = holdout['X'].index)\n",
    "df_2020 = holdout['X'].copy()\n",
    "df_2020['probs']   = probs \n",
    "def risk_thresh(p):\n",
    "    if p < 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df_2020['at_risk'] = (df_2020['probs'].apply(risk_thresh))\n",
    "df_2020.head()\n",
    "df_2020.to_csv('michelin_2020_model_data.csv')\n",
    "not_at_risk = probs[probs > 0]\n",
    "\n",
    "main_points = ['total_median', 'total_slope','div4_food_quality', 'div4_menu',  'div4_service', 'div4_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout['X'].loc[at_risk.index.values][main_points]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_at_risk = pd.concat([not_at_risk, holdout['X'].loc[not_at_risk.index.values]], axis = 1)\n",
    "at_risk     = pd.concat([at_risk, holdout['X'].loc[at_risk.index.values]], axis = 1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_risk.columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'seaborn' has no attribute 'set_axis_bgcolor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-259-56c5a455af7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Blues_d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis_bgcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lightslategray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# ax.grid(False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# ax.set(xlabel='common xlabel', ylabel='Profit')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'seaborn' has no attribute 'set_axis_bgcolor'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [1, 2, 3, 4]\n",
    "y = [100, 120, 140, 200]\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.barplot(X, y, palette = 'Blues_d')\n",
    "sns.set_style('white')\n",
    "sns.set_axis_bgcolor(\"lightslategray\")\n",
    "# ax.grid(False)\n",
    "# ax.set(xlabel='common xlabel', ylabel='Profit')\n",
    "# plt.savefig('michelin_profit_4.png', format='png', dpi=1000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
